<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>t4t CHI 2025 workshop proposal</title>
    <link rel="stylesheet" href="style.css">
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
</head>
<body>
<h1><strong>Tools for Thought</strong></h1>
<p>Research and Design for Understanding,
  Protecting, and Augmenting Human Cognition with Generative
  AI</p>
<h2> Call for Participation</h2>
<p>We are pleased to invite position papers for the half-day workshop on <em>"Tools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI"</em> at CHI 2025.</p>
<p>The workshop is intended for researchers and practitioners from industry or academia working in Human-Computer Interaction, Arts, Ethics, Social Sciences, Design, and Psychology. We also welcome contributions from anyone working on topics related to human cognition and AI.</p>
<p>Workshop participants are encouraged to submit position papers that highlight interesting points of discussion, opinions, open research questions, and ongoing or planned research. We accept position papers between 2-4 pages in length, formatted according to the SIGCHI template (\documentclass[sigconf,screen]{acmart}). Topics of interest for the position papers include but are not limited to:</p>
<ul>
  <li>Topic 1</li>
</ul>
<p>All submissions will be reviewed based on relevance to the conference theme - "Understanding,
  Protecting, and Augmenting Human Cognition with Generative
AI" as well as quality and diversity.  At least one author of each accepted paper must register for the workshop.</p>
<p>For question or paper submissions please contact: something@somethingelse.com</p>
<p>The list of accepted papers will be posted on the website and will be available for download prior to the workshop.</p>
<h2>Abstract</h2>
<p>We invite researchers, designers, practitioners, and provocateurs to explore what it means to understand and shape the impact of Generative AI (GenAI) on human cognition. GenAI radically widens the scope and capability of automation for work, learning, and creativity. While impactful, it also changes workflows and the quality of thinking involved, raising questions about its effects on cognition, including critical thinking and learning. Yet, GenAI also offers opportunities for designing tools for thought that protect and augment cognition. Such systems provoke critical thinking, provide personalized tutoring, or enable novel ways of sensemaking, among other approaches. How does GenAI change workflows and human cognition? What are opportunities and challenges for designing GenAI systems that protect and augment human cognition? Which theories, perspectives, and methods are relevant? This workshop aims to develop a multidisciplinary community interested in exploring these questions to protect against the erosion, and fuel the augmentation, of human cognition using GenAI.</p>
<h2>Workshop Aims [Roll into CfP]</h2>
<p>With GenAI&rsquo;s rapid real-world adoption and the proliferation of GenAI-driven systems, now is the time to initiate a dedicated effort in understanding what this means for human cognition, and how we can shape this technology for our wide-ranging benefit. The CHI community has both the duty and the means to explore this. This effort requires multi-disciplinary collaboration. CHI is a unique venue that brings together not only HCI technical system designers, developers, and engineers, but also those from psychology, linguistics, anthropology, sociology, learning science, communications, management, science studies, history, and policy, among others. Similar efforts have arisen in the past, with areas such as Explainable AI  and Responsible AI  developing strong communities of interest and numerous resources.</p>
<p>Cognitive concepts have been alluded to in these contexts, but have not been their core focus—in contrast, our effort is distinctly concerned with the impacts of GenAI on human cognition and the implications for the way people learn, build skills, and grow expertise. Thus, this workshop has two aims: </p>
<ol>
  <li>As the initial instance of an anticipated series, we want to identify and coalesce a multidisciplinary community interested in understanding and shaping the impact of GenAI on human cognition.</li>
  <li>We want to map the space of opportunities in this area, in terms of the following high-level questions:
    <ul>
      <li>How do GenAI systems change workflows? What activities become more or less important? What activities are eliminated and created?</li>
      <li>What is the impact of current GenAI paradigms on human cognition, such as our ability to learn, think critically and creatively, reason, remember, and do sensemaking in contexts from creative art to programming or scientific research? How can we better understand and mitigate potential negative impacts, and maximize positive impacts? • What does it mean to protect and augment human cognition?</li>
      <li>What are opportunities and challenges for designing GenAI systems that protect and augment human cognition? How do we develop principles or guidelines for doing so?</li>
      <li>Which contemporary and historical theories and perspectives—from across disciplines—are relevant for understanding the impact of GenAI on cognition and workflows, and for designing GenAI systems that protect and augment human cognition?</li>
      <li>How do we study the impact of current GenAI paradigms and novel GenAI systems for protecting and augmenting human cognition?</li>
    </ul>
  </li>
	</ol>
<p>Given the breadth and complexity of these questions, we do not expect this initial workshop to provide definitive answers to the above, but rather to initiate focused conversations that lay the groundwork for addressing these questions as a community.</p>
<p>An underlying aim of this workshop and its community is to strengthen the link between understanding the impact of GenAI on cognition and designing new systems that protect and augment cognition. For example, exploring foundational theories and approaches to studying impact from across relevant disciplines is not only useful for its own sake, but will provide principled grounds for designing novel GenAI systems and evaluating their afforded experiences and effectiveness. The connection between descriptive theories and prescriptive design is illustrated in recent studies on AI-enabled tutoring systems, which examine the impact of current GenAI systems on learning, harness pedagogical principles to inform the design of new systems, and conduct comparative evaluations. There are similar opportunities for designing GenAI systems that support critical thinking  or sensemaking  in knowledge work. CHI&rsquo;s multidisciplinary community, its focus on contextual understanding of technologies, and its strength in designing real-world systems, therefore make it the ideal venue for this workshop.</p>
<h2>Key Dates</h2>
<p>Deadline for submissions:<br>
Notifications of acceptance:<br>
Camera-ready:<br>
Day of Workshop:</p>
<h2>Workshop Program</h2>
<p>09:00 - 09:30 (30min) Welcome, ice-breaker, and coffee <br>
09:30 - 10:45 (75min) Lightning talks + panel discussion: Impact of GenAI on Cognition and Workflows 1<br>
0:45 - 11:15 (30min) Coffee break and informal demos <br>
11:15 - 12:30 (75min) Lightning talks + panel discussion: Methods and Theories <br>
12:30 - 14:00 (90min) Lunch break (informal networking and discussion) <br>
14:00 - 15:15 (75min) Lightning talks + panel discussion: Designing for Cognitive Protection and Augmentation<br>
15:15 - 15:45 (30min) Coffee break and informal demos<br>
15:45 - 17:00 (75min) Co-ideation session: Mapping Opportunities<br>
17:00 - 17:30 (30min) Next steps and closing</p>
<h2>Organizers</h2>
<p>Lev Tankelevitch is a Senior Researcher in Microsoft Research, within the Tools for Thought group. His research explores how to augment human agency in collaborative knowledge work, including using metacognition as a lens to understand and improve human-AI interaction, and to design GenAI systems that improve intentionality in collaboration. He has a background in applied behavioural science, having previously worked at the Behavioural Insights Team, and in cognitive psychology and neuroscience. Find more about his work here: https://aka.ms/levt. </p>
<p>Elena Glassman is an Assistant Professor at Harvard University&rsquo;s Paulson School Of Engineering and Applied Sciences. Her research focuses on building AI-resilient interfaces that support meta-cognition through a variety of novel interface features and affordances that enhance user&rsquo;s reading, writing, and sensemaking abilities. These features Manuscript submitted to ACM 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 Tools for Thought with Generative AI 5 include constructive antagonism [16] and reifying (1) multiple recursive levels of detail [33], (2) natural language commands as dynamically generated UI widgets [78], and (3) pre-computed similarities and distinctions across many items in a corpus at both the literal and analogical levels, e.g., OverCode [30], Examplore [31], ParaLib [85], and Positional Diction Clustering [28]. Her group specializes in leveraging theories of human cognition about how humans form mental models from varying concrete examples.</p>
<p>Aniket Kittur is a Professor in the Human-Computer Interaction Institute in Carnegie Mellon&rsquo;s School of Computer Science. His research explores combining human and machine intelligence to scale up sensemaking and innovation in domains including scientific literature, decision making, productivity, and analogical design. </p>
<p>Mina Lee is an Assistant Professor in Computer Science, Data Science Institute, and Cognitive Science (affiliated) at the University of Chicago. Her research centers around Writing with AI, especially how AI is transforming our writing process, the content we produce, and our identities as writers. She was named one of MIT Technology Review&rsquo;s Korean Innovators under 35 in 2022. She has co-founded and organized workshops on Intelligent and Interactive Writing Assistants (In2Writing) and Human-centered Evaluation and Auditing of Language Models (HEAL) at ACL 2022, CHI 2023, and CHI 2024. </p>
<p>Srishti Palani is a Senior Researcher at Tableau Research. She researches at the intersection of Cognitive Science, Human-Centered AI and Human-Computer Interaction. Her research investigates how people think and behave while exploring, sensemaking and being creative and with Generative AI and information on the Web. Based on this understanding of user behaviors and cognition, she builds interactive intelligent systems that augment these human cognitive abilities. She earned her doctorate and master&rsquo;s from the University of California, San Diego. Before PhD, she graduated summa cum laude double majoring in Computer Science and Psychology (specializing in Cognitive Neuroscience) from Mount Holyoke College. </p>
<p>Majeed Kazemitabaar is a PhD candidate at University of Toronto, where he is researching on and developing tools that balance productivity and cognitive engagement in AI-assisted programming. He has studied the impact of learning to code with AI on subsequent performance without AI, to measure the effects of overreliance on AI [43, 44]. He has developed and evaluated programming tools based on the concept of &ldquo;Friction-Induced AI&rdquo; to achieve two goals: enhancing short-term productivity by improving verification through added intervention points [45], and preventing long-term productivity loss by requiring user engagement with AI-generated code [46]. </p>
<p>Jessica He is a UX Designer at IBM Research, where she is a member of the Human-AI Collaboration team. Her work focuses on leveraging design to bridge the gap between user expectations and emerging AI technologies, encompassing topics including AI attribution, risk mitigation, and enhancing knowledge work [34]. By applying user-centered methods, she strives to create - and guide other practitioners in creating - trustworthy generative AI applications that augment rather than replace human capabilities and collaboration [81]. </p>
<p>Gonzalo Ramos is a Principal Researcher at Microsoft Research at Redmond. He is part of the Human Centered AI and Experiences Group at Microsoft Research at Redmond, where he works at the intersection of HCI, Design, and AI to augment people&rsquo;s agencies and capabilities. He is a graduate from the University of Toronto&rsquo;s DGP lab, as well as the Universidad de Buenos Aires. Prior to his position at Microsoft Research, he worked as a Senior Design Technologist and later UX Scientist at Amazon, and as a Scientist at Microsoft. You can find more information on his work here: https://www.microsoft.com/en-us/research/people/goramos/. </p>
<p>Advait Sarkar is a researcher at Microsoft, affiliated lecturer at the University of Cambridge, and honorary lecturer at University College London. He studies the effects of Generative AI on knowledge work [62, 75], programming [48, 64], and data analysis [23, 26, 45, 50]. He is part of the Tools for Thought group at Microsoft [59], where he leads a research Manuscript submitted to ACM 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 6 Tankelevitch et al. agenda aimed at enhancing critical thinking with Generative AI [66, 67]. His article &ldquo;AI Should Challenge, Not Obey&rdquo; appears in the October 2024 issue of Communications of the ACM [65]. </p>
<p>Yvonne Rogers is a Professor of Interaction Design at University College London. A central theme of her work is concerned with designing AI that augments human cognition. She have given many keynotes and invited talks on how HCI can meet AI in the I. </p>
<p>Hari Subramonyam is an Assistant Professor (Research) at Stanford Graduate School of Education and Computer Science (by courtesy). He is also the Ram and Vijay Sriram Faculty Fellow at the Stanford Institute for HumanCentered AI. Subramonyam studies ways to augment human learning using AI by (1) engaging in cognitively informed design practices, (2) co-designing with learners and educators, and (3) developing transformative AI-enabled learning experiences. Through his research, he also contributes tools and methodologies that prioritize ethical considerations, responsible design practices, and human values when creating AI experiences. </p>
</body>
</html>
